{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import pylab as pl\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heler Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary2index(var):\n",
    "    if var.ndim == 1:\n",
    "        return np.sum(np.power(2, np.arange(len(var))) * var).astype(int)\n",
    "    elif var.ndim == 2:\n",
    "        return np.sum(\n",
    "            np.power(2, np.arange(var.shape[0]))[:, np.newaxis] * var, axis=0\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        print(\"why more than 2 dimensions?\")\n",
    "\n",
    "\n",
    "def index2binary(var, n_all_agents):\n",
    "    if np.isscalar(var):\n",
    "        return (var & (1 << np.arange(n_all_agents))) > 0\n",
    "    elif var.ndim == 1:\n",
    "        return (var[np.newaxis, :] & (1 << np.arange(n_all_agents)[:, np.newaxis])) > 0\n",
    "    else:\n",
    "        print(\"why more than 1 dimensions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bit Flip Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BF:\n",
    "    def __init__(self, n_actions, n_teams, team_size, policy_seed, avg_pairwise_correlation = 0.5, method=\"sum\"):\n",
    "        self.nA = n_actions\n",
    "        self.n_teams = n_teams\n",
    "        self.team_size = team_size\n",
    "        self.all_agents = n_teams * team_size + 1\n",
    "        self.all_other_agents = self.all_agents - 1\n",
    "        self.nS = self.nA ** (self.all_agents)\n",
    "        self.policy_seed = policy_seed\n",
    "        self.corr = avg_pairwise_correlation\n",
    "        self.method = method\n",
    "        self.policies = None\n",
    "        self.rng = np.random.default_rng(self.policy_seed)\n",
    "        self.agent_1_policy = self.rng.integers(0, 2, 2 ** (self.all_agents), dtype=bool)\n",
    "        self.get_other_agent_policies(gen_type=self.method)\n",
    "\n",
    "    def get_other_agent_policies(\n",
    "        self,\n",
    "        gen_type=\"sum\",\n",
    "        ):\n",
    "        self.policies = np.zeros(self.nS, dtype=int)\n",
    "\n",
    "        rng = np.random.default_rng(self.policy_seed)\n",
    "        agent_indices_bool = np.zeros(self.all_other_agents, dtype=bool)\n",
    "\n",
    "        rho_normaldist = np.sin(np.pi / 2 * self.corr)\n",
    "        batch_size = np.min((int(2 ** 25), self.nS))\n",
    "        tmp_policies = np.zeros((self.all_other_agents, batch_size), dtype=bool)\n",
    "        for batch_idx in range(int(self.nS / batch_size)):\n",
    "            for team in range(self.n_teams):\n",
    "                agent_indices = range(team * self.team_size, (team + 1) * self.team_size)\n",
    "                agent_indices_bool[agent_indices] = True\n",
    "\n",
    "                if (\n",
    "                    gen_type == \"mix\"\n",
    "                ):  # Bernoulli mixture of independent and identical binary RVs\n",
    "                    is_same = self.corr > self.rng.random(batch_size)\n",
    "                    n_same = np.sum(is_same)\n",
    "                    n_diff = batch_size - n_same\n",
    "                    tmp_policies[np.ix_(agent_indices_bool, is_same)] = self.rng.integers(\n",
    "                        0, 2, n_same\n",
    "                    )[np.newaxis, :]\n",
    "                    tmp_policies[np.ix_(agent_indices_bool, ~is_same)] = self.rng.integers(\n",
    "                        0, 2, [self.team_size, n_diff]\n",
    "                    )\n",
    "                elif (\n",
    "                    gen_type == \"sum\"\n",
    "                ):  # signed sum of independent and identical normal RVs\n",
    "                    tmp_policies[agent_indices_bool, :] = (\n",
    "                        np.sqrt(1 - rho_normaldist)\n",
    "                        * rng.normal(size=(self.team_size, batch_size))\n",
    "                        + np.sqrt(rho_normaldist)\n",
    "                        * rng.normal(size=batch_size)[np.newaxis, :]\n",
    "                    ) > 0\n",
    "                else:\n",
    "                    print(\"choose sum or mix\")\n",
    "\n",
    "                agent_indices_bool[agent_indices] = False\n",
    "            self.policies[\n",
    "                batch_idx * batch_size: (batch_idx + 1) * batch_size\n",
    "            ] = binary2index(\n",
    "                np.vstack(\n",
    "                    (\n",
    "                        self.agent_1_policy[\n",
    "                            batch_idx * batch_size: (batch_idx + 1) * batch_size\n",
    "                        ],\n",
    "                        tmp_policies,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def get_reward(self, agent_index, state):\n",
    "        fraction = state.sum()/len(state)\n",
    "        reward = 1.0 / (fraction*int(state[agent_index]) + (1-fraction)*int(1-state[agent_index]))\n",
    "        return reward\n",
    "\n",
    "    def P(self, s, a):\n",
    "        next_state = self.policies[s]\n",
    "        next_state = index2binary(next_state, self.all_agents)\n",
    "        next_state[0] = a\n",
    "        prob = 1.0 # transitions are deterministic\n",
    "        reward = self.get_reward(agent_index=0, state=next_state) # get reward for agent 0\n",
    "        return prob, next_state, reward\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        # return state 0 by deafult\n",
    "        self.state = 0\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, theta=0.0001, discount_factor=1.0, max_iterations=100000):\n",
    "    \"\"\"\n",
    "    Value Iteration Algorithm.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (policy, V) of the optimal policy and the optimal value function.\n",
    "    \"\"\"\n",
    "    V_history = []\n",
    "\n",
    "    def one_step_lookahead(state, V):\n",
    "        \"\"\"\n",
    "        Helper function to calculate the value for all action in a given state.\n",
    "        \n",
    "        Args:\n",
    "            state: The state to consider (int)\n",
    "            V: The value to use as an estimator, Vector of length env.nS\n",
    "        \n",
    "        Returns:\n",
    "            A vector of length env.nA containing the expected value of each action.\n",
    "        \"\"\"\n",
    "        A = np.zeros(env.nA)\n",
    "        for a in range(env.nA):\n",
    "            for prob, next_state, reward in [env.P(state, a)]:\n",
    "                next_state = binary2index(next_state)\n",
    "                # print(\"next state index is \", next_state)\n",
    "                A[a] += prob * (reward + discount_factor * V[next_state])\n",
    "        return A\n",
    "    \n",
    "    V = np.zeros(env.nS)\n",
    "    time_step = 0\n",
    "    \n",
    "    while True:\n",
    "        # Stopping condition\n",
    "        time_step += 1\n",
    "        delta = 0\n",
    "\n",
    "        # Update each state...\n",
    "        # TODO: randmized order\n",
    "        r_list = np.arange(env.nS)\n",
    "        np.random.shuffle(r_list)\n",
    "        for s in r_list:\n",
    "            # Do a one-step lookahead to find the best action\n",
    "            A = one_step_lookahead(s, V)\n",
    "            best_action_value = np.max(A)\n",
    "            # Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
    "            # Update the value function. Ref: Sutton book eq. 4.10. \n",
    "            V[s] = best_action_value  \n",
    "\n",
    "        # save sweep \n",
    "        V_history.append(np.mean(V))\n",
    "        # Check if we can stop \n",
    "        if delta < theta:\n",
    "            # print(\"converged\", time_step, end=\"\\n\", flush=True)\n",
    "            break\n",
    "        if time_step >= max_iterations:\n",
    "            # print(\"max iterations reached\", time_step, end=\"\\n\", flush=True)\n",
    "            break\n",
    "\n",
    "        # if time_step % 100 == 0:\n",
    "            # print(\"time step \", time_step)\n",
    "            # print(V[:10])\n",
    "\n",
    "    # Create a deterministic policy using the optimal value function\n",
    "    policy = np.zeros(env.nS, dtype='int')\n",
    "    for s in range(env.nS):\n",
    "        # One step lookahead to find the best action for this state\n",
    "        A = one_step_lookahead(s, V)\n",
    "        best_action = np.argmax(A)\n",
    "        # Always take the best action\n",
    "        # A[0] corresponds to action 0 and A[1] corresponds to action 1, therefore instead of the one-hot value we use the index of the best action\n",
    "        policy[s] = best_action\n",
    "    \n",
    "    return policy, V, V_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "seed_list = np.random.randint(0, 2**32, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2357136044, 2546248239, 3071714933, 3626093760, 2588848963,\n",
       "       3684848379, 2340255427, 3638918503, 1819583497, 2678185683])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team size  5  n_teams  1  rho  0.0  seed  2357136044\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 647\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1170\n",
      "team size  5  n_teams  1  rho  0.0  seed  2546248239\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 626\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "converged 1096\n",
      "team size  5  n_teams  1  rho  0.0  seed  3071714933\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 691\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 664\n",
      "team size  5  n_teams  1  rho  0.0  seed  3626093760\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 647\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "converged 893\n",
      "team size  5  n_teams  1  rho  0.0  seed  2588848963\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 678\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 674\n",
      "team size  5  n_teams  1  rho  0.0  seed  3684848379\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 644\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 791\n",
      "team size  5  n_teams  1  rho  0.0  seed  2340255427\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 766\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1169\n",
      "team size  5  n_teams  1  rho  0.0  seed  3638918503\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 671\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 647\n",
      "team size  5  n_teams  1  rho  0.0  seed  1819583497\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 666\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 668\n",
      "team size  5  n_teams  1  rho  0.0  seed  2678185683\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 671\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 710\n",
      "team size  5  n_teams  1  rho  0.5  seed  2357136044\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1167\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1161\n",
      "team size  5  n_teams  1  rho  0.5  seed  2546248239\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1165\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 662\n",
      "team size  5  n_teams  1  rho  0.5  seed  3071714933\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1155\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 670\n",
      "team size  5  n_teams  1  rho  0.5  seed  3626093760\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 723\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1179\n",
      "team size  5  n_teams  1  rho  0.5  seed  2588848963\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1156\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1166\n",
      "team size  5  n_teams  1  rho  0.5  seed  3684848379\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 726\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1152\n",
      "team size  5  n_teams  1  rho  0.5  seed  2340255427\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1112\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 719\n",
      "team size  5  n_teams  1  rho  0.5  seed  3638918503\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "converged 700\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1159\n",
      "team size  5  n_teams  1  rho  0.5  seed  1819583497\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 744\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 764\n",
      "team size  5  n_teams  1  rho  0.5  seed  2678185683\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1162\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1160\n",
      "team size  5  n_teams  1  rho  1.0  seed  2357136044\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1117\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1105\n",
      "team size  5  n_teams  1  rho  1.0  seed  2546248239\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "converged 1095\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1113\n",
      "team size  5  n_teams  1  rho  1.0  seed  3071714933\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1103\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1124\n",
      "team size  5  n_teams  1  rho  1.0  seed  3626093760\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "converged 1094\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "converged 1079\n",
      "team size  5  n_teams  1  rho  1.0  seed  2588848963\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "converged 1081\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1112\n",
      "team size  5  n_teams  1  rho  1.0  seed  3684848379\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1163\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1118\n",
      "team size  5  n_teams  1  rho  1.0  seed  2340255427\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1102\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "converged 1092\n",
      "team size  5  n_teams  1  rho  1.0  seed  3638918503\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 792\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1120\n",
      "team size  5  n_teams  1  rho  1.0  seed  1819583497\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 773\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "converged 772\n",
      "team size  5  n_teams  1  rho  1.0  seed  2678185683\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1151\n",
      "time step  100\n",
      "time step  200\n",
      "time step  300\n",
      "time step  400\n",
      "time step  500\n",
      "time step  600\n",
      "time step  700\n",
      "time step  800\n",
      "time step  900\n",
      "time step  1000\n",
      "time step  1100\n",
      "converged 1110\n",
      "CPU times: user 1min 26s, sys: 7.18 s, total: 1min 33s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_dict = {}\n",
    "# for team_size, n_teams in [(5,1), (10,1),(15,1), (20,1)]:\n",
    "for team_size, n_teams in [(5,1)]:\n",
    "    result_dict[(team_size, n_teams)] = {}\n",
    "    for rho in [0.0, 0.5, 1.0]:\n",
    "        result_dict[(team_size, n_teams)][rho] = {}\n",
    "        # TODO: remove :3 after testing\n",
    "        for seed in seed_list[:3]:\n",
    "            print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
    "            result_dict[(team_size, n_teams)][rho][seed] = {}\n",
    "            env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
    "            env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
    "            policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
    "            result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
    "            policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
    "            result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sims(team_tuple, rho_list, seed_list):\n",
    "    result_dict = {}\n",
    "    for team_size, n_teams in team_tuple:\n",
    "        result_dict[(team_size, n_teams)] = {}\n",
    "        for rho in rho_list:\n",
    "            result_dict[(team_size, n_teams)][rho] = {}\n",
    "            for seed in seed_list:\n",
    "                # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
    "                result_dict[(team_size, n_teams)][rho][seed] = {}\n",
    "                env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
    "                env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
    "                policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
    "                result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
    "                policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
    "                result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged 647\n",
      "converged 1170\n"
     ]
    }
   ],
   "source": [
    "mydict = run_sims([(5,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 3.97052 s\n",
      "File: /var/folders/27/bskdj9jn79lclxwd3s0t9bxw0000gn/T/ipykernel_47270/384736207.py\n",
      "Function: run_sims at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def run_sims(team_tuple, rho_list, seed_list):\n",
      "     2         1          1.0      1.0      0.0      result_dict = {}\n",
      "     3         2          2.0      1.0      0.0      for team_size, n_teams in team_tuple:\n",
      "     4         1          0.0      0.0      0.0          result_dict[(team_size, n_teams)] = {}\n",
      "     5         2          0.0      0.0      0.0          for rho in rho_list:\n",
      "     6         1          1.0      1.0      0.0              result_dict[(team_size, n_teams)][rho] = {}\n",
      "     7         2          6.0      3.0      0.0              for seed in seed_list:\n",
      "     8                                                           # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
      "     9         1          1.0      1.0      0.0                  result_dict[(team_size, n_teams)][rho][seed] = {}\n",
      "    10         1        643.0    643.0      0.0                  env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
      "    11         1        880.0    880.0      0.0                  env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
      "    12         1    1420368.0 1420368.0     35.8                  policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
      "    13         1          2.0      2.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
      "    14         1    2548612.0 2548612.0     64.2                  policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
      "    15         1          3.0      3.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
      "    16                                           \n",
      "    17         1          0.0      0.0      0.0      return result_dict"
     ]
    }
   ],
   "source": [
    "%lprun -f run_sims run_sims([(5,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 6.38773 s\n",
      "File: /var/folders/27/bskdj9jn79lclxwd3s0t9bxw0000gn/T/ipykernel_47270/384736207.py\n",
      "Function: run_sims at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def run_sims(team_tuple, rho_list, seed_list):\n",
      "     2         1          1.0      1.0      0.0      result_dict = {}\n",
      "     3         2          1.0      0.5      0.0      for team_size, n_teams in team_tuple:\n",
      "     4         1          1.0      1.0      0.0          result_dict[(team_size, n_teams)] = {}\n",
      "     5         2          1.0      0.5      0.0          for rho in rho_list:\n",
      "     6         1          0.0      0.0      0.0              result_dict[(team_size, n_teams)][rho] = {}\n",
      "     7         2          7.0      3.5      0.0              for seed in seed_list:\n",
      "     8                                                           # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
      "     9         1          1.0      1.0      0.0                  result_dict[(team_size, n_teams)][rho][seed] = {}\n",
      "    10         1       1588.0   1588.0      0.0                  env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
      "    11         1        574.0    574.0      0.0                  env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
      "    12         1    3418115.0 3418115.0     53.5                  policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
      "    13         1          3.0      3.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
      "    14         1    2967436.0 2967436.0     46.5                  policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
      "    15         1          3.0      3.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
      "    16                                           \n",
      "    17         1          0.0      0.0      0.0      return result_dict"
     ]
    }
   ],
   "source": [
    "%lprun -f run_sims run_sims([(6,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 11.9599 s\n",
      "File: /var/folders/27/bskdj9jn79lclxwd3s0t9bxw0000gn/T/ipykernel_47270/384736207.py\n",
      "Function: run_sims at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def run_sims(team_tuple, rho_list, seed_list):\n",
      "     2         1          1.0      1.0      0.0      result_dict = {}\n",
      "     3         2          0.0      0.0      0.0      for team_size, n_teams in team_tuple:\n",
      "     4         1          0.0      0.0      0.0          result_dict[(team_size, n_teams)] = {}\n",
      "     5         2          1.0      0.5      0.0          for rho in rho_list:\n",
      "     6         1          1.0      1.0      0.0              result_dict[(team_size, n_teams)][rho] = {}\n",
      "     7         2          3.0      1.5      0.0              for seed in seed_list:\n",
      "     8                                                           # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
      "     9         1          1.0      1.0      0.0                  result_dict[(team_size, n_teams)][rho][seed] = {}\n",
      "    10         1       1376.0   1376.0      0.0                  env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
      "    11         1        321.0    321.0      0.0                  env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
      "    12         1    5992744.0 5992744.0     50.1                  policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
      "    13         1          5.0      5.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
      "    14         1    5965470.0 5965470.0     49.9                  policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
      "    15         1          3.0      3.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
      "    16                                           \n",
      "    17         1          0.0      0.0      0.0      return result_dict"
     ]
    }
   ],
   "source": [
    "%lprun -f run_sims run_sims([(7,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 24.9472 s\n",
      "File: /var/folders/27/bskdj9jn79lclxwd3s0t9bxw0000gn/T/ipykernel_47270/384736207.py\n",
      "Function: run_sims at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def run_sims(team_tuple, rho_list, seed_list):\n",
      "     2         1          1.0      1.0      0.0      result_dict = {}\n",
      "     3         2          2.0      1.0      0.0      for team_size, n_teams in team_tuple:\n",
      "     4         1          1.0      1.0      0.0          result_dict[(team_size, n_teams)] = {}\n",
      "     5         2          2.0      1.0      0.0          for rho in rho_list:\n",
      "     6         1          1.0      1.0      0.0              result_dict[(team_size, n_teams)][rho] = {}\n",
      "     7         2          5.0      2.5      0.0              for seed in seed_list:\n",
      "     8                                                           # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
      "     9         1          1.0      1.0      0.0                  result_dict[(team_size, n_teams)][rho][seed] = {}\n",
      "    10         1       1150.0   1150.0      0.0                  env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
      "    11         1        495.0    495.0      0.0                  env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
      "    12         1   12357976.0 12357976.0     49.5                  policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
      "    13         1          4.0      4.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
      "    14         1   12587593.0 12587593.0     50.5                  policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
      "    15         1          2.0      2.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
      "    16                                           \n",
      "    17         1          0.0      0.0      0.0      return result_dict"
     ]
    }
   ],
   "source": [
    "%lprun -f run_sims run_sims([(8,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 53.6273 s\n",
      "File: /var/folders/27/bskdj9jn79lclxwd3s0t9bxw0000gn/T/ipykernel_47270/384736207.py\n",
      "Function: run_sims at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def run_sims(team_tuple, rho_list, seed_list):\n",
      "     2         1          1.0      1.0      0.0      result_dict = {}\n",
      "     3         2          5.0      2.5      0.0      for team_size, n_teams in team_tuple:\n",
      "     4         1          1.0      1.0      0.0          result_dict[(team_size, n_teams)] = {}\n",
      "     5         2          9.0      4.5      0.0          for rho in rho_list:\n",
      "     6         1          0.0      0.0      0.0              result_dict[(team_size, n_teams)][rho] = {}\n",
      "     7         2          4.0      2.0      0.0              for seed in seed_list:\n",
      "     8                                                           # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
      "     9         1          1.0      1.0      0.0                  result_dict[(team_size, n_teams)][rho][seed] = {}\n",
      "    10         1        868.0    868.0      0.0                  env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
      "    11         1        665.0    665.0      0.0                  env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
      "    12         1   28388224.0 28388224.0     52.9                  policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
      "    13         1         13.0     13.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
      "    14         1   25237473.0 25237473.0     47.1                  policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
      "    15         1          5.0      5.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
      "    16                                           \n",
      "    17         1          0.0      0.0      0.0      return result_dict"
     ]
    }
   ],
   "source": [
    "%lprun -f run_sims run_sims([(9,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 102.791 s\n",
      "File: /var/folders/27/bskdj9jn79lclxwd3s0t9bxw0000gn/T/ipykernel_47270/384736207.py\n",
      "Function: run_sims at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def run_sims(team_tuple, rho_list, seed_list):\n",
      "     2         1          1.0      1.0      0.0      result_dict = {}\n",
      "     3         2          1.0      0.5      0.0      for team_size, n_teams in team_tuple:\n",
      "     4         1          1.0      1.0      0.0          result_dict[(team_size, n_teams)] = {}\n",
      "     5         2          2.0      1.0      0.0          for rho in rho_list:\n",
      "     6         1          1.0      1.0      0.0              result_dict[(team_size, n_teams)][rho] = {}\n",
      "     7         2         11.0      5.5      0.0              for seed in seed_list:\n",
      "     8                                                           # print(\"team size \", team_size, \" n_teams \", n_teams, \" rho \", rho, \" seed \", seed)\n",
      "     9         1          1.0      1.0      0.0                  result_dict[(team_size, n_teams)][rho][seed] = {}\n",
      "    10         1       1286.0   1286.0      0.0                  env_sum = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"sum\")\n",
      "    11         1       6146.0   6146.0      0.0                  env_mix = BF(n_actions=2, n_teams=n_teams, team_size=team_size, avg_pairwise_correlation=rho, policy_seed=seed, method=\"mix\")\n",
      "    12         1   50400476.0 50400476.0     49.0                  policy_sum, V_sum, V_sum_hist = value_iteration(env_sum, discount_factor=0.99, max_iterations=10000)\n",
      "    13         1         20.0     20.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"sum\"] = [policy_sum, V_sum, V_sum_hist]\n",
      "    14         1   52383424.0 52383424.0     51.0                  policy_mix, V_mix, V_mix_hist = value_iteration(env_mix, discount_factor=0.99, max_iterations=10000)\n",
      "    15         1         20.0     20.0      0.0                  result_dict[(team_size, n_teams)][rho][seed][\"mix\"] = [policy_mix, V_mix, V_mix_hist]\n",
      "    16                                           \n",
      "    17         1          1.0      1.0      0.0      return result_dict"
     ]
    }
   ],
   "source": [
    "%lprun -f run_sims run_sims([(10,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f run_sims run_sims([(10,1)], [0.0], seed_list[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many minut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_rand.p', 'wb') as fp:\n",
    "    pickle.dump(result_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('result.p', 'rb') as fp:\n",
    "#     result_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "columns = set()\n",
    "data_sum = []\n",
    "data_mix = []\n",
    "\n",
    "for i, pair in enumerate(result_dict):\n",
    "    for j, rho in enumerate(result_dict[pair]):\n",
    "        rows.append(pair + (rho,))\n",
    "        for seed in result_dict[pair][rho]:\n",
    "            columns.add((seed,))\n",
    "            n_all_agents = pair[0] * pair[1] + 1\n",
    "            a = np.arange(0, 2**(n_all_agents))\n",
    "            b = index2binary(a, n_all_agents)\n",
    "            optimal_p = (b.sum(axis=0) < n_all_agents/2)\n",
    "            learned_p_mix= np.array(result_dict[pair][rho][seed][\"mix\"][0], dtype=bool)\n",
    "            learned_p_sum = np.array(result_dict[pair][rho][seed][\"sum\"][0], dtype=bool)\n",
    "\n",
    "            data_sum.append(np.mean(learned_p_sum == optimal_p))\n",
    "            data_mix.append(np.mean(learned_p_mix == optimal_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.array([i for (i,) in columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array(rows)\n",
    "columns = np.array(columns)\n",
    "data_sum = np.array(data_sum).reshape(rows.shape[0], columns.shape[0])\n",
    "data_mix = np.array(data_mix).reshape(rows.shape[0], columns.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# hide axes\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "ax.table(cellText=data_sum,\n",
    "        rowLabels=rows,\n",
    "        colLabels=columns,\n",
    "        loc='center')\n",
    "\n",
    "fig.suptitle(\"Sum\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"table_sum.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# hide axes\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "ax.table(cellText=data_sum,\n",
    "        rowLabels=rows,\n",
    "        colLabels=columns,\n",
    "        loc='center')\n",
    "\n",
    "fig.suptitle(\"Mix\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"table_mix.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sum, ax_sum = plt.subplots(2, 3, figsize=(16, 12), sharex=True, sharey=True)\n",
    "fig_mix, ax_mix = plt.subplots(2, 3, figsize=(16, 12), sharex=True, sharey=True)\n",
    "\n",
    "for i, pair in enumerate(result_dict):\n",
    "    for j, rho in enumerate(result_dict[pair]):\n",
    "        ax_sum[i][j].set_title(\"team size {}, n_teams {}, rho {}\".format(pair[0], pair[1], rho))\n",
    "        ax_sum[i][j].set_xlabel(\"iterations\")\n",
    "        ax_sum[i][j].set_ylabel(\"mean V\")\n",
    "\n",
    "        ax_mix[i][j].set_title(\"team size {}, n_teams {}, rho {}\".format(pair[0], pair[1], rho))\n",
    "        ax_mix[i][j].set_xlabel(\"iterations\")\n",
    "        ax_mix[i][j].set_ylabel(\"mean V\")\n",
    "\n",
    "        for seed in result_dict[pair][rho]:\n",
    "            ax_sum[i][j].plot(result_dict[pair][rho][seed][\"sum\"][2], label=\"f{}\".format(seed))\n",
    "            ax_mix[i][j].plot(result_dict[pair][rho][seed][\"mix\"][2], label=\"f{}\".format(seed))\n",
    "            \n",
    "            # ax_sum[i][j].legend()\n",
    "            # ax_mix[i][j].legend()\n",
    "fig_sum.suptitle(\"sum\")\n",
    "fig_mix.suptitle(\"mix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sum.tight_layout()\n",
    "fig_sum.savefig(\"fig_sum.pdf\")\n",
    "fig_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mix.tight_layout()\n",
    "fig_mix.savefig(\"fig_mix.pdf\")\n",
    "fig_mix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sum, ax_sum = plt.subplots(1, 2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "fig_mix, ax_mix = plt.subplots(1, 2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "colors = [\"blue\", \"green\", \"orange\", \"purple\", \"black\"]\n",
    "blue_patch = mpatches.Patch(color='blue', label='The blue data')\n",
    "green_patch = mpatches.Patch(color='green', label='The green data')\n",
    "orange_patch = mpatches.Patch(color='orange', label='The orange data')\n",
    "\n",
    "rho_list = result_dict[pair].keys()\n",
    "\n",
    "for i, pair in enumerate(result_dict):\n",
    "    ax_sum[i].set_title(\"team size {}, n_teams {}\".format(pair[0], pair[1]))\n",
    "    ax_sum[i].set_xlabel(\"iteration\")\n",
    "    ax_sum[i].set_ylabel(\"log normalized V\")\n",
    "    ax_mix[i].set_title(\"team size {}, n_teams {}\".format(pair[0], pair[1]))\n",
    "    ax_mix[i].set_xlabel(\"iteration\")\n",
    "    ax_mix[i].set_ylabel(\"log normalized V\")\n",
    "    \n",
    "    for j, rho in enumerate(result_dict[pair]):\n",
    "        for seed in result_dict[pair][rho]:\n",
    "            V_mix_hist = result_dict[pair][rho][seed][\"sum\"][2]\n",
    "            V_sum_hist = result_dict[pair][rho][seed][\"mix\"][2]\n",
    "\n",
    "            normalized_V_mix_hist = [abs(V_mix_hist[i]-V_mix_hist[-1])/(V_mix_hist[-1] - V_mix_hist[0]) for i in range(len(V_mix_hist))]\n",
    "            normalized_V_sum_hist = [abs(V_sum_hist[i]-V_sum_hist[-1])/(V_sum_hist[-1] - V_sum_hist[0]) for i in range(len(V_sum_hist))]\n",
    "\n",
    "            line_sum = ax_sum[i].plot(normalized_V_mix_hist, color=colors[j])\n",
    "            line_mix = ax_mix[i].plot(normalized_V_sum_hist, color=colors[j])\n",
    "            \n",
    "    ax_sum[i].set_yscale('log')\n",
    "    ax_mix[i].set_yscale('log')\n",
    "\n",
    "fig_sum.legend([blue_patch, green_patch, orange_patch], rho_list)\n",
    "fig_mix.legend([blue_patch, green_patch, orange_patch], rho_list)\n",
    "fig_sum.suptitle(\"sum\")\n",
    "fig_mix.suptitle(\"mix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sum.tight_layout()\n",
    "fig_sum.savefig(\"fig_time_sum.pdf\")\n",
    "fig_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mix.tight_layout()\n",
    "fig_mix.savefig(\"fig_time_mix.pdf\")\n",
    "fig_mix.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(16, 12), sharex=True, sharey=True)\n",
    "\n",
    "for i, pair in enumerate(result_dict):\n",
    "    for j, rho in enumerate(result_dict[pair]):\n",
    "        ax[i][j].set_title(\"team size {}, n_teams {}, rho {}\".format(pair[0], pair[1], rho))\n",
    "        ax[i][j].set_xlabel(\"seed\")\n",
    "        ax[i][j].set_ylabel(\"log of normalized timescale\")\n",
    "\n",
    "        timescales = []\n",
    "        for seed in result_dict[pair][rho]:\n",
    "            timescales.append(len(result_dict[pair][rho][seed][\"het\"][2]))\n",
    "            # ax[i][j].plot(result_dict[pair][rho][seed][\"het\"][2], label=\"f{}\".format(seed))\n",
    "            # ax_het[i][j].plot(result_dict[pair][rho][seed][\"het\"][2], label=\"f{}\".format(seed))\n",
    "            # ax[i][j].legend()\n",
    "            # ax_het[i][j].legend()\n",
    "        timescales.sort()\n",
    "        normalized_timescales = [(t-timescales[0])/(timescales[-1] - timescales[0]) for t in timescales]\n",
    "        log_norm_t = [np.log(t) for t in normalized_timescales]\n",
    "        # print(timescales)\n",
    "        print(normalized_timescales)\n",
    "        ax[i][j].plot(log_norm_t)\n",
    "\n",
    "\n",
    "# fig.suptitle(\"homogeneous\")\n",
    "# fig_het.suptitle(\"heterogeneous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bit Flip Environment (Old One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MABitFlipEnv:\n",
    "\n",
    "    def __init__(self, n_actions, n_agents, n_memory, n_teams, avg_pairwise_correlation = 0.5, is_het=False):\n",
    "        self.nA = n_actions\n",
    "        self.n_agents = n_agents\n",
    "        self.n_memory = n_memory\n",
    "        self.nS = self.nA ** (self.n_agents * self.n_memory)\n",
    "        self.nS_plus = self.nA * self.nS\n",
    "        self.state = None\n",
    "        self.n_teams = n_teams\n",
    "        self.is_het = is_het\n",
    "        self.avg_pairwise_correlation = avg_pairwise_correlation\n",
    "        self.policies = np.zeros((self.n_agents, self.nS),dtype=bool)\n",
    "        self.joint_action_seqs = []\n",
    "        self.calculate_policies()\n",
    "\n",
    "    def get_hom_policies(self):\n",
    "        team_size = int(self.n_agents/self.n_teams)\n",
    "        rng = np.random.default_rng(12345)\n",
    "        agent_indices_bool = np.zeros(self.n_agents,dtype=bool)\n",
    "        for team in range(self.n_teams):\n",
    "            agent_indices = range(team * team_size, (team+1) * team_size)\n",
    "            agent_indices_bool[agent_indices]=True\n",
    "            #joint actions for a group are assigned Bernoulli: {as same over the group, else random}\n",
    "            is_same = (self.avg_pairwise_correlation > rng.random(self.nS)) #TODO: add more than binary ations is_same=(avg_pairwise_correlation>np.random.rand(0, n_actions, n_states)) #joint actions for a group are assigned as same over the group, else random\n",
    "            n_same = np.sum(is_same)\n",
    "            n_diff = self.nS-n_same\n",
    "            self.policies[np.ix_(agent_indices_bool, is_same)] = np.random.randint(0, self.nA, n_same)[np.newaxis,:]\n",
    "            self.policies[np.ix_(agent_indices_bool, ~is_same)] = np.random.randint(0, self.nA, [team_size,n_diff])\n",
    "            agent_indices_bool[agent_indices] = False #reset\n",
    "\n",
    "    def get_het_policies(self):\n",
    "        team_size = int(self.n_agents/self.n_teams)\n",
    "        rng = np.random.default_rng(12345)\n",
    "        agent_indices_bool = np.zeros(self.n_agents, dtype=bool)\n",
    "        rho=np.sin(np.pi/2*self.avg_pairwise_correlation)\n",
    "        for team in range(self.n_teams):\n",
    "            agent_indices = range(team * team_size, (team+1) * team_size)\n",
    "            agent_indices_bool[agent_indices]=True\n",
    "            self.policies[agent_indices_bool, :] = ((np.sqrt(1 - rho)*rng.normal(size = (team_size, self.nS)) + np.sqrt(rho)*rng.normal(size = self.nS)[np.newaxis,:]) > 0)\n",
    "            agent_indices_bool[agent_indices] = False\n",
    "\n",
    "    def calculate_policies(self):\n",
    "        if self.is_het:\n",
    "            self.get_het_policies()\n",
    "        else:\n",
    "            self.get_hom_policies()\n",
    "\n",
    "    def get_reward(self, agent_index, s_plus):\n",
    "        fraction = s_plus.sum()/len(s_plus)\n",
    "        reward = 1.0 / (fraction*int(s_plus[agent_index]) + (1-fraction)*int(1-s_plus[agent_index]))\n",
    "        return reward\n",
    "\n",
    "    def P(self, s, a):\n",
    "        next_state = self.policies[:, s]\n",
    "        next_s_plus = np.insert(next_state, 0, a)\n",
    "        prob = 1.0 # transitions are deterministic\n",
    "        reward = self.get_reward(0, next_s_plus) # get reward for agent 0\n",
    "        return prob, next_s_plus, reward\n",
    "    \n",
    "    def step(self, a):\n",
    "        next_state = self.policies[:, self.state]\n",
    "        self.state = binary2index(next_state)\n",
    "        next_s_plus = np.insert(next_state, 0, a)\n",
    "        reward = self.get_reward(0, next_s_plus)\n",
    "        return next_s_plus, reward\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        # return state 0 by deafult\n",
    "        self.state = 0\n",
    "        return self.state"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "519c3646e46e87a9b4521f30b0c71a5bab07601a45b52f63f01adb46cf5a2090"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('marl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
