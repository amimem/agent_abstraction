{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading human plays' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# games_jsons = []\n",
    "# ix = 0\n",
    "# with open(\"../data/diplomacy-v1-27k-msgs/standard_no_press.jsonl\", \"r\") as json_file:\n",
    "#     for line in json_file:\n",
    "#         games_jsons.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json data\n",
    "completed = False\n",
    "games_jsons = []\n",
    "with open(\"../data/diplomacy-v1-27k-msgs/standard_no_press.jsonl\", \"r+b\") as json_file:\n",
    "    with mmap.mmap(json_file.fileno(), length=0, access=mmap.ACCESS_READ) as mmap_object:\n",
    "        for i, line in enumerate(iter(mmap_object.readline, b\"\")):\n",
    "            tmp = json.loads(line.decode(\"utf-8\"))\n",
    "            if tmp[\"map\"] == \"standard\":\n",
    "                if completed:\n",
    "                    for phase in tmp[\"phases\"]:\n",
    "                        if phase[\"name\"] == \"COMPLETED\":\n",
    "                            games_jsons.append(tmp)\n",
    "                else:\n",
    "                    games_jsons.append(tmp)\n",
    "            if len(games_jsons) == 30:\n",
    "                print(\"last game id is\", i)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncomment to load RL single game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# games_jsons = []\n",
    "# json_file_path = \"../data/game_rl_0.json\"\n",
    "\n",
    "# with open(json_file_path, 'r') as j:\n",
    "#       games_jsons.append(json.loads(j.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a pandas dataframe\n",
    "df = pd.DataFrame(games_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df[\"map\"] == \"standard\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = df['phases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in games:\n",
    "    for ix, iy in enumerate(game):\n",
    "        game[ix]['phase_id'] = ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(input):\n",
    "    out = {}\n",
    "    out['game_id'] = input['state']['game_id']\n",
    "    out['phase_id'] = input['phase_id']\n",
    "    out['phase_name'] = input['name']\n",
    "    results_units_keys = [x for x in input['results']]\n",
    "\n",
    "    assert input['orders'].items() \n",
    "    for player, orders in input['orders'].items():\n",
    "        if orders is not None:\n",
    "            if orders:\n",
    "                for order in orders:\n",
    "                    out['coordinator'] = player\n",
    "                    out['type'] = order.split()[0]\n",
    "                    out['current_location'] = order.split()[1]\n",
    "                    out['action'] = order.split()[2]\n",
    "                    unit = order.split()[0]+ ' ' + order.split()[1]\n",
    "                    # print(\"unit result is: \", unit , unit in results_units, results_units)\n",
    "                    if input['results']:\n",
    "                        out['results'] = input['results'][unit]\n",
    "                    else:\n",
    "                        print(\"empty results\")\n",
    "                        print(order)\n",
    "                    if unit in results_units_keys:\n",
    "                        results_units_keys.remove(unit)\n",
    "                    out['impact_location'] = []\n",
    "                    if out['action'] == '-' or out['action'] == 'R':\n",
    "                        assert len(order.split()) == 4 or len(order.split()) == 5, order\n",
    "                        out['impact_location'] = order.split()[3]\n",
    "                    yield(out)\n",
    "                \n",
    "            else:\n",
    "                # uncmomment these if you need a row for empty orders (in group by you will get 1 instead of 0)\n",
    "                # out['coordinator'] = player\n",
    "                # out['type'] = -1\n",
    "                # out['current_location'] = -1\n",
    "                # out['action'] = -1\n",
    "                # out['results'] = -1\n",
    "                # out['impact_location'] = -1\n",
    "                # if out['action'] == '-' or out['action'] == 'R':\n",
    "                #     assert len(order.split()) == 4 or len(order.split()) == 5, order\n",
    "                #     out['impact_location'] = order.split()[3]\n",
    "                # yield(out)\n",
    "                pass\n",
    "\n",
    "    if len(results_units_keys)>0:\n",
    "        # uncomment for completed games\n",
    "        all_orders = [order for order in input['orders'].values()]\n",
    "        total_len = 0\n",
    "        for l in all_orders:\n",
    "            total_len += len(l)\n",
    "        if total_len == 0:\n",
    "            print(out)\n",
    "        assert [order for order in input['orders'].values()]\n",
    "        for unit in results_units_keys:\n",
    "            if unit == 'WAIVE': ## FIXME: double check this later\n",
    "                continue\n",
    "            assert len(unit.split()) == 2, unit\n",
    "            out['coordinator'] = 'RA'\n",
    "            for player in input[\"state\"][\"units\"]:\n",
    "                if unit in input[\"state\"][\"units\"][player]:\n",
    "                    out['coordinator'] = player\n",
    "\n",
    "            if len(unit.split()[0]) != 1: # if we have sth like HOL D: \"void\"\n",
    "                assert input['results'][unit][0] == 'void', input['results'][unit]\n",
    "                location = unit.split()[0]\n",
    "                assert unit.split()[1] == 'D', unit.split()[1]\n",
    "                # find the corresponding key in the results\n",
    "                for key in input['results']:\n",
    "                    if key.split()[1] == location:\n",
    "                        assert input['results'][key][0] == \"disband\", input['results'][key]\n",
    "                        input['results'][key].append(input['results'][unit][0])\n",
    "                        break\n",
    "            else:\n",
    "                out['type'] = unit.split()[0]\n",
    "                out['current_location'] = unit.split()[1]\n",
    "                out['results'] = input['results'][unit]\n",
    "                out['action'] = -2\n",
    "                out['impact_location'] = -2\n",
    "                yield(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = []\n",
    "for idx, game in enumerate(games):\n",
    "  for idx, phase in enumerate(game):\n",
    "    row_generator = flatten_json(phase)\n",
    "    assert row_generator is not None, row_generator\n",
    "    for row in row_generator:\n",
    "      all_records.append(row.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.DataFrame.from_records(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loc[complete_df['coordinator'] == 'RA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['unique_unit_id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glaSz65KoHy4"
   },
   "outputs": [],
   "source": [
    "def assign_unit_id(phase_df, source_unit_id_map, dest_unit_id_map, _id):\n",
    "\n",
    "    # fror each row in the phase df\n",
    "    for idx, row in phase_df.iterrows():\n",
    "\n",
    "        # if current location or type of army in invalid skip the row (we only deal with valid orders)\n",
    "        if row['action'] == -1 or row['type'] == 'N':\n",
    "            continue\n",
    "        \n",
    "        # get the current location of the unit\n",
    "        source_unit = row['type'] + ' ' + row['current_location']\n",
    "\n",
    "        # if the location is not in the map, add it to the map (in other phases the same unit can be used, hence checking the condition _ dictionaries are global, have data across phases)\n",
    "        if source_unit not in source_unit_id_map:\n",
    "            source_unit_id_map[source_unit] = _id\n",
    "            _id += 1\n",
    "\n",
    "        # destination dict is synced with source dict after the loop, so that we can use updated info at the beginning of each assignment\n",
    "        # row['unique_unit_id'] = source_unit_id_map[source_unit]\n",
    "        phase_df.loc[idx,'unique_unit_id'] = source_unit_id_map[source_unit]\n",
    "\n",
    "        if row['action'] == '-':\n",
    "            result = row['results']\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    dest_location = row['impact_location']\n",
    "                    try:\n",
    "                        dest_unit = row['type'] + ' ' + dest_location\n",
    "                    except:\n",
    "                        print(\"dest location error\", row)\n",
    "                        return\n",
    "                    if dest_unit not in dest_unit_id_map:\n",
    "                        dest_unit_id_map[dest_unit] = source_unit_id_map.pop(source_unit)\n",
    "                        # source_unit_id_map[source_unit]\n",
    "                        # print(source_unit_id_map.pop(source_unit))\n",
    "                elif 'disband' in result:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                    \n",
    "        elif row['action'] == 'R':\n",
    "            result = row['results']\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    dest_location = row['impact_location']\n",
    "                    dest_unit = row['type'] + ' ' + dest_location\n",
    "                    if dest_unit not in dest_unit_id_map:\n",
    "                        dest_unit_id_map[dest_unit] = source_unit_id_map.pop(source_unit)\n",
    "                elif 'disband' in result:\n",
    "                    if len(result) > 1:\n",
    "                        if 'void' in result:\n",
    "                                print(result)\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "\n",
    "        elif row['action'] == 'D':\n",
    "            result = row['results']\n",
    "            assert source_unit in source_unit_id_map\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                elif 'void' in result:\n",
    "                    print(\"void disband\", row)\n",
    "        \n",
    "        elif row['action'] == 'B':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        elif row['action'] == 'H':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        elif row['action'] == 'S':\n",
    "            assert source_unit in source_unit_id_map\n",
    "        \n",
    "        elif row['action'] == 'C':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        # for added result rows\n",
    "        elif row['action'] == -2:\n",
    "            result = row['results']\n",
    "            assert source_unit in source_unit_id_map\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                elif 'disband' in result and 'void' not in result:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                    # print(\"disband\")\n",
    "                elif 'disband' in result and 'void' in result:\n",
    "                    # print(\"void disband\")\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"invalid action\", row)\n",
    "\n",
    "    # merge the source and destination dictionaries into one\n",
    "    source_unit_id_map.update(dest_unit_id_map)\n",
    "    # remove the destination dict (values get updated based on old data if we don't do this)\n",
    "    dest_unit_id_map = {}\n",
    "\n",
    "    return source_unit_id_map, dest_unit_id_map, _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games = complete_df[\"game_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_phase_df_list = []\n",
    "for idx, game_id in enumerate(unique_games):\n",
    "    print(idx, game_id)\n",
    "    s_dict = {}\n",
    "    d_dict = {}\n",
    "    _id = 1\n",
    "    game_df = complete_df.loc[complete_df[\"game_id\"].apply(lambda x: x == game_id)]\n",
    "    unique_phases = game_df['phase_id'].unique()\n",
    "    for phase in unique_phases:\n",
    "        condition = game_df[\"phase_id\"].apply(lambda x: x == phase)\n",
    "        phase_df = game_df.loc[condition]\n",
    "        s_dict, d_dict, _id = assign_unit_id(phase_df, s_dict, d_dict, _id)\n",
    "        game_phase_df_list.append(phase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf = pd.concat(game_phase_df_list, ignore_index=True)\n",
    "cdf = pd.concat(game_phase_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the concatenated df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce to only 2 seasons per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_fall_phases=(cdf['phase_name'].apply(lambda x:x[0])!='W') & (cdf['phase_name'].apply(lambda x:x[-1])!='R') & (cdf['phase_name'].apply(lambda x:x[-1]) == 'M')\n",
    "cdf2=cdf[spring_fall_phases].copy()\n",
    "cdf2.phase_name=cdf2.phase_name.apply(lambda x: float(x[1:-1]+('.0' if x[0]=='S' else '.5')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute a binary winner label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_series=pd.Series(index=cdf.game_id.unique())\n",
    "for game_id in winner_series.index:\n",
    "    tmax=cdf2[cdf2.game_id==game_id].phase_id.max()\n",
    "    final_units=cdf2[(cdf2.game_id==game_id) & (cdf2.phase_id==tmax)].groupby('coordinator').unique_unit_id.nunique()\n",
    "    winner_series[game_id]=final_units.idxmax() if len(final_units)>0 else np.nan\n",
    "def dummy(row,winner_series):\n",
    "    return row.coordinator==winner_series[row.game_id]\n",
    "from functools import partial\n",
    "part_dummy=partial(dummy,winner_series=winner_series)\n",
    "cdf2['winner']=cdf2.apply(part_dummy,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view winning stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute winner loser plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitcounts=cdf2.groupby([\"game_id\",\"coordinator\",\"phase_name\",\"winner\"])[\"unique_unit_id\"].nunique()\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "# winlose_data.groupby(['winner','phase_name']).mean().unstack().T.plot(legend=False,xticks=np.arange(1900,1920,5))\n",
    "fig,ax=pl.subplots(1,1,figsize=(3,3))#ensemble statistics\n",
    "sns.lineplot(ax=ax,\n",
    "             x='phase_name',\n",
    "             y='unique_unit_id',\n",
    "             data=unitcounts.reset_index().drop(labels=['game_id','coordinator'],axis=1),\n",
    "             hue=r'winner',\n",
    "             ci='sd',\n",
    "             palette=sns.color_palette(\"colorblind\", 2))\n",
    "h,l=ax.get_legend_handles_labels()\n",
    "ax.legend(handles=h[1:][::-1],labels=['winners','losers'],frameon=False)\n",
    "ax.grid()\n",
    "ax.set_yticks(np.arange(0,20,2))\n",
    "ax.set_yticklabels([0,'',4,'',8,'',12,'',16,''])\n",
    "ax.set_xticks(np.arange(1901,1919,4))\n",
    "ax.set_ylabel('number of units')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylim(0,18)\n",
    "ax.set_xlim(1901,1918)\n",
    "# fig.savefig('winners_and_losers.pdf',format='pdf',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loc[complete_df[\"game_id\"] == 'uXFQ2zgI-DUrgwlS']['phase_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.loc[cdf['coordinator'] == 'RA'][:40].sort_values(by=['phase_id', 'unique_unit_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.loc[cdf['game_id'] == 'lVp6PZxk3Jpufc9Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_fall_phases=(cdf['phase_name'].apply(lambda x:x[0])!='W') & (cdf['phase_name'].apply(lambda x:x[-1])!='R') & (cdf['phase_name'].apply(lambda x:x[-1]) == 'M')\n",
    "cdf[spring_fall_phases].groupby([\"game_id\",\"coordinator\",\"phase_name\"])[\"unique_unit_id\"].nunique().unstack().T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[spring_fall_phases].groupby([\"game_id\",\"coordinator\",\"phase_name\"])[\"unique_unit_id\"].nunique().unstack().head(14)\n",
    "cdf.groupby([\"game_id\",\"coordinator\",\"phase_id\"])[\"unique_unit_id\"].nunique().unstack().head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd=(cdf['phase_name'].apply(lambda x:x[0])!='W') & (cdf['phase_name'].apply(lambda x:x[-1])!='R') & (cdf['game_id'].apply(lambda x: x == '0yv59hl6e5Ensb4M') )\n",
    "cdf[cnd].groupby([\"game_id\",\"coordinator\",\"phase_id\"])[\"unique_unit_id\"].nunique().unstack().head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[spring_fall_phases].loc[cdf[\"game_id\"] == \"0yv59hl6e5Ensb4M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a single game to JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = \"uXFQ2zgI-DUrgwlS\"\n",
    "for game in games_jsons:\n",
    "    if game['id'] == game_id:\n",
    "        json.dump(game, open(f'{game_id}.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate different triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single game:\n",
    "game_id = \"lVp6PZxk3Jpufc9Z\"\n",
    "game_df = cdf.loc[cdf[\"game_id\"] == game_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[\"unique_unit_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[\"unique_unit_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.loc[game_df[\"unique_unit_id\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = game_df[\"coordinator\"].unique()\n",
    "assert len(players) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_units = {}\n",
    "for player in players:\n",
    "    player_units[player] = game_df.loc[game_df[\"coordinator\"] == player][\"unique_unit_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/45655936/how-to-test-all-items-of-a-list-are-disjoint\n",
    "# make sure some units are handed over to other players\n",
    "\n",
    "import itertools\n",
    "def all_disjoint(iterables):\n",
    "    merged = itertools.chain(*iterables)\n",
    "    total = list(merged)\n",
    "    total.sort()\n",
    "    print(total)\n",
    "    print(set(total))\n",
    "    return len(total) == len(set(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_units = list(player_units.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disjoint(all_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_two_players = set(itertools.permutations(player_units.keys(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_two_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Triple = namedtuple('Triple', ['triple', 'player_i', 'player_j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "for player_i, player_j in unique_two_players:\n",
    "    if player_i== \"TURKEY\" and player_j == \"AUSTRIA\":\n",
    "        print(player_i, player_j)\n",
    "        p_units = list(itertools.combinations(player_units[player_i], 2))\n",
    "        o_unit = list(itertools.combinations(player_units[player_j], 1))\n",
    "        # get all 3-tuples unique combinations\n",
    "        p_o_product = list(itertools.product(p_units, o_unit))\n",
    "        p_o_product = [(a, b, c) for (a,b), (c,) in p_o_product]\n",
    "        triple = [Triple(t, player_i, player_j) for t in p_o_product]\n",
    "        triples.append(triple)\n",
    "        # first tuple in the product belongs to player_i and the other belongs to player_j\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triple(p_1_name='TURKEY', p1_val=(1,2), p2_name='AUSTRIA', p2_val=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_units = list(itertools.combinations(player_units[\"TURKEY\"], 2))\n",
    "o_unit = list(itertools.combinations(player_units[\"AUSTRIA\"], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = itertools.product(p_units, [\"TURKEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _tuple in enumerate(all_tuples):\n",
    "    all_tuples[i] = _tuple[0] + _tuple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_units = set(itertools.combinations([1,2,3], 2))\n",
    "# o_unit = set(itertools.combinations([4,5], 1))\n",
    "\n",
    "# # get all 3-tuples unique combinations\n",
    "# all_tuples = list(itertools.product(p_units, o_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-remove-duplicate-tuples-from-list-of-tuples/\n",
    "def removeDuplicates(lst):\n",
    "    return list(set([i for i in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_tuples = removeDuplicates(all_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_unique_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in all_unique_tuples:\n",
    "    print(triple)\n",
    "    condition = game_df[\"unique_unit_id\"].apply(lambda x: x in triple)\n",
    "    presence = game_df[condition]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence.sort_values(['unique_unit_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence[presence[\"unique_unit_id\"] == 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence[presence[\"unique_unit_id\"] == 22][\"phase_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = presence[\"phase_name\"].value_counts() == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_phases = presence.loc[presence[\"phase_name\"].apply(lambda x: x in phases and phases[x])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ids = eligible_phases[\"phase_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ids = old_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = np.arange(1, len(old_ids)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_ids = presence.loc[presence[\"phase_name\"].apply(lambda x: x in phases and phases[x])].phase_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_ids.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_ids.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in unique_games:\n",
    "    game_df = cdf.loc[cdf[\"game_id\"] == game_id]\n",
    "    assert game_df[\"unique_unit_id\"].nunique() == game_df[\"unique_unit_id\"].max(), game_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "for game_id in unique_games:\n",
    "    game_df = cdf.loc[cdf[\"game_id\"] == game_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Deepmind's Diplomacy trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_outputs = np.load(file='../data/actions_outputs.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_outputs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(action_outputs[0][0]).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions = np.load(file='../data/legal_actions.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legal_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.load(file='../data/observations.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_outputs = np.load(file='../data/step_outputs.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(step_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_outputs[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "519c3646e46e87a9b4521f30b0c71a5bab07601a45b52f63f01adb46cf5a2090"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
