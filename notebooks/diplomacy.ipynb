{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Deepmind's Diplomacy trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_outputs = np.load(file='../data/actions_outputs.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_outputs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(action_outputs[0][0]).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions = np.load(file='../data/legal_actions.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legal_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.load(file='../data/observations.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_outputs = np.load(file='../data/step_outputs.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(step_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading human plays' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json data\n",
    "games_jsons = []\n",
    "with open(\"../data/diplomacy-v1-27k-msgs/standard_no_press.jsonl\", \"r+b\") as json_file:\n",
    "    with mmap.mmap(json_file.fileno(), length=0, access=mmap.ACCESS_READ) as mmap_object:\n",
    "        for i, line in enumerate(iter(mmap_object.readline, b\"\")):\n",
    "            games_jsons.append(json.loads(line.decode(\"utf-8\")))\n",
    "            if i == 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a pandas dataframe\n",
    "df = pd.DataFrame(games_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"map\"] == \"standard\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = df['phases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in games:\n",
    "    for ix, iy in enumerate(game):\n",
    "        game[ix]['phase_id'] = ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(nested_json):\n",
    "    out = {}\n",
    "    x = nested_json\n",
    "    \n",
    "    out['game_id'] = x['state']['game_id']\n",
    "    out['phase_id'] = x['phase_id']\n",
    "    out['phase_name'] = x['name']\n",
    "    results_units = [x for x in x['results']]\n",
    "    # print(\"results are: \", results_units)\n",
    "    assert x['orders'].items() \n",
    "    for key, value in x['orders'].items():\n",
    "        if value is None:\n",
    "            # out['coordinator'] = key\n",
    "            # out['type'] = 'N'\n",
    "            # out['current_location'] = 'N'\n",
    "            # out['action'] = 'N'\n",
    "            # out['results'] = 'N'\n",
    "            # out['via'] = 'N'\n",
    "            # out['impact_location'] = 'N'\n",
    "            # yield(out)\n",
    "            pass\n",
    "        else:\n",
    "            if value:\n",
    "                for ix in value:\n",
    "                    out['coordinator'] = key\n",
    "                    out['type'] = ix.split()[0]\n",
    "                    out['current_location'] = ix.split()[1]\n",
    "                    out['action'] = ix.split()[2]\n",
    "                    unit = ix.split()[0]+ ' ' + ix.split()[1]\n",
    "                    # print(\"unit result is: \", unit , unit in results_units, results_units)\n",
    "                    if x['results']:\n",
    "                        out['results'] = x['results'][unit]\n",
    "                    else:\n",
    "                        print(\"empty results\")\n",
    "                        print(ix)\n",
    "                    if unit in results_units:\n",
    "                        results_units.remove(unit)\n",
    "                    # out['via'] = 'N'\n",
    "                    out['impact_location'] = []\n",
    "                    if out['action'] == '-' or out['action'] == 'R':\n",
    "                        assert len(ix.split()) == 4 or len(ix.split()) == 5, ix\n",
    "                        out['impact_location'] = ix.split()[3]\n",
    "                        # if ix.split()[-1] == 'VIA':\n",
    "                        #     out['via'] = ix.split()[-1]\n",
    "                    yield(out)\n",
    "\n",
    "    if len(results_units)>0:\n",
    "        # print(\"adding new rows: \", results_units)\n",
    "        for ix in results_units:\n",
    "            out['coordinator'] = 'N'\n",
    "            for key in x[\"state\"][\"units\"]:\n",
    "                if ix in x[\"state\"][\"units\"][key]:\n",
    "                    # print(key, value, \"found\")\n",
    "                    out['coordinator'] = key\n",
    "            out['type'] = ix.split()[0] if len(ix.split()) > 1 else 'N'\n",
    "            out['current_location'] = ix.split()[1] if len(ix.split()) > 1 else ix\n",
    "            out['action'] = 'N'\n",
    "            out['results'] = x['results'][ix]\n",
    "            # out['via'] = 'N'\n",
    "            out['impact_location'] = 'N'\n",
    "            yield(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.DataFrame()\n",
    "for idx, game in enumerate(games):\n",
    "  # print(\"game \", idx)\n",
    "  for idx, phase in enumerate(game):\n",
    "    # print(\"phase \", idx)\n",
    "    row_i = flatten_json(phase)\n",
    "    if row_i != None:\n",
    "      for ix in row_i:  \n",
    "        row_df = pd.DataFrame(ix.items()).T\n",
    "        complete_df = pd.concat((complete_df,row_df), axis=0, ignore_index=True)\n",
    "\n",
    "new_header = complete_df.iloc[0] #grab the first row for the header\n",
    "complete_df = complete_df[1:] #take the data less the header row\n",
    "complete_df.columns = new_header #set the header row as the df header\n",
    "complete_df = complete_df.loc[::2]\n",
    "complete_df = complete_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['unique_unit_id'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glaSz65KoHy4"
   },
   "outputs": [],
   "source": [
    "def assign_unit_id(phase_df, source_unit_id_map, dest_unit_id_map, _id):\n",
    "\n",
    "    # fror each row in the phase df\n",
    "    for idx, row in phase_df.iterrows():\n",
    "\n",
    "        # if current location or type of army in invalid skip the row (we only deal with valid orders)\n",
    "        if row['current_location'] == 'N' or row['type'] == 'N':\n",
    "            continue\n",
    "        \n",
    "        # get the current location of the unit\n",
    "        source_unit = row['type'] + ' ' + row['current_location']\n",
    "\n",
    "        # if the location is not in the map, add it to the map (in other phases the same unit can be used, hence checking the condition _ dictionaries are global, have data across phases)\n",
    "        if source_unit not in source_unit_id_map:\n",
    "            source_unit_id_map[source_unit] = _id\n",
    "            _id += 1\n",
    "\n",
    "        # destination dict is synced with source dict after the loop, so that we can use updated info at the beginning of each assignment\n",
    "        # row['unique_unit_id'] = source_unit_id_map[source_unit]\n",
    "        phase_df.loc[idx,'unique_unit_id'] = source_unit_id_map[source_unit]\n",
    "\n",
    "\n",
    "        # print(idx, row)\n",
    "\n",
    "        if row['action'] == '-':\n",
    "            result = row['results']\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    dest_location = row['impact_location']\n",
    "                    try:\n",
    "                        dest_unit = row['type'] + ' ' + dest_location\n",
    "                    except:\n",
    "                        print(\"dest location error\", row)\n",
    "                        return\n",
    "                    if dest_unit not in dest_unit_id_map:\n",
    "                        dest_unit_id_map[dest_unit] = source_unit_id_map[source_unit]\n",
    "                        source_unit_id_map.pop(source_unit)\n",
    "                elif 'disband' in result:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                    \n",
    "        elif row['action'] == 'R':\n",
    "            result = row['results']\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    dest_location = row['impact_location']\n",
    "                    dest_unit = row['type'] + ' ' + dest_location\n",
    "                    if dest_unit not in dest_unit_id_map:\n",
    "                        dest_unit_id_map[dest_unit] = source_unit_id_map[source_unit]\n",
    "                        source_unit_id_map.pop(source_unit)\n",
    "                elif 'disband' in result:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "\n",
    "        elif row['action'] == 'D':\n",
    "            source_unit_id_map.pop(source_unit)\n",
    "        \n",
    "        elif row['action'] == 'B':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        # phase_df.loc[idx] = row\n",
    "\n",
    "    # merge the source and destination dictionaries into one\n",
    "    source_unit_id_map.update(dest_unit_id_map)\n",
    "    # remove the destination dict (values get updated based on old data if we don't do this)\n",
    "    dest_unit_id_map = {}\n",
    "\n",
    "    return phase_df, source_unit_id_map, dest_unit_id_map, _id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games = complete_df[\"game_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[complete_df[\"game_id\"] == 'uXFQ2zgI-DUrgwlS']['phase_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_phase_df_list = []\n",
    "for idx, game_id in enumerate(unique_games):\n",
    "    print(idx, game_id)\n",
    "    s_dict = {}\n",
    "    d_dict = {}\n",
    "    _id = 1\n",
    "    unique_phases = complete_df[complete_df[\"game_id\"] == game_id]['phase_id'].unique()\n",
    "    for phase in unique_phases:\n",
    "        # print(\"phase number is\", phase)\n",
    "        phase_df = complete_df[complete_df[\"phase_id\"] == phase]\n",
    "        res_df, s_dict, d_dict, _id = assign_unit_id(phase_df, s_dict, d_dict, _id)\n",
    "        game_phase_df_list.append(phase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.concat(game_phase_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf[cdf[\"game_id\"] == \"uXFQ2zgI-DUrgwlS\"].sort_values(by=['phase_id', 'coordinator']).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out_df.txt', 'w') as f:\n",
    "    print(cdf.groupby([\"game_id\",\"coordinator\",\"phase_id\"])[\"unique_unit_id\"].nunique().to_string(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[complete_df[\"game_id\"] == 'Fdp3XM14WLTn5vBF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "519c3646e46e87a9b4521f30b0c71a5bab07601a45b52f63f01adb46cf5a2090"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('marl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
