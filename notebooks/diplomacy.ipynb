{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading human plays' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mmap\n",
    "import json\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json data\n",
    "def load_jsonl(path: str, num_games: int = 30, mmap: bool = False, completed_only: bool = False):\n",
    "    '''\n",
    "    Loads the jsonl data from the given path.\n",
    "    If num_games is not -1, only the first num_games games are loaded.\n",
    "    If mmap is True, the data is memory mapped.\n",
    "    If completed_only is True, only completed games are loaded.\n",
    "    '''\n",
    "    games_jsons = []\n",
    "    with open(path, \"r+b\") as json_file:\n",
    "        if mmap:\n",
    "            with mmap.mmap(json_file.fileno(), length=0, access=mmap.ACCESS_READ) as mmap_object:\n",
    "                for i, line in enumerate(iter(mmap_object.readline, b\"\")):\n",
    "                    tmp = json.loads(line.decode(\"utf-8\"))\n",
    "                    if tmp[\"map\"] == \"standard\":\n",
    "                        if completed_only:\n",
    "                            for phase in tmp[\"phases\"]:\n",
    "                                if phase[\"name\"] == \"COMPLETED\":\n",
    "                                    games_jsons.append(tmp)\n",
    "                        else:\n",
    "                            games_jsons.append(tmp)\n",
    "\n",
    "                    if num_games != -1 and len(games_jsons) == num_games:\n",
    "                        print(\"last game id is\", i)\n",
    "                        break\n",
    "        else:\n",
    "            for i, line in enumerate(json_file):\n",
    "                tmp = json.loads(line.decode(\"utf-8\"))\n",
    "                if tmp[\"map\"] == \"standard\":\n",
    "                    if completed_only:\n",
    "                        for phase in tmp[\"phases\"]:\n",
    "                            if phase[\"name\"] == \"COMPLETED\":\n",
    "                                games_jsons.append(tmp)\n",
    "                    else:\n",
    "                        games_jsons.append(tmp)\n",
    "\n",
    "                if num_games != -1 and len(games_jsons) == num_games:\n",
    "                    print(\"last game id is\", i)\n",
    "                    break\n",
    "\n",
    "    return games_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/diplomacy-v1-27k-msgs/standard_no_press.jsonl\"\n",
    "games_jsons = load_jsonl(path, num_games=100, mmap=False, completed_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a pandas dataframe\n",
    "df = pd.DataFrame(games_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = df['phases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in games:\n",
    "    for ix, iy in enumerate(game):\n",
    "        game[ix]['phase_id'] = ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(input):\n",
    "    out = {}\n",
    "    out['game_id'] = input['state']['game_id']\n",
    "    out['phase_id'] = input['phase_id']\n",
    "    out['phase_name'] = input['name']\n",
    "    results_units_keys = [x for x in input['results']]\n",
    "\n",
    "    assert input['orders'].items() \n",
    "    for player, orders in input['orders'].items():\n",
    "        if orders is not None:\n",
    "            if orders:\n",
    "                for order in orders:\n",
    "                    out['coordinator'] = player\n",
    "                    out['type'] = order.split()[0]\n",
    "                    out['current_location'] = order.split()[1]\n",
    "                    out['action'] = order.split()[2]\n",
    "                    unit = order.split()[0]+ ' ' + order.split()[1]\n",
    "                    # print(\"unit result is: \", unit , unit in results_units, results_units)\n",
    "                    if input['results']:\n",
    "                        # if the action is retreat, we have to check the units in the state to see if there are only one occurance available for the unit\n",
    "                        # if out['action'] == 'R':\n",
    "                        #     all_units = input['state']['units'].values()\n",
    "                        #     if unit in all_units:\n",
    "                        #         assert len(input['results'][unit]) == 0, \"retreat should not have results\"\n",
    "                        #         out['result'] = [\"void\"]\n",
    "                        out['results'] = input['results'][unit]\n",
    "                    else:\n",
    "                        print(\"empty results\")\n",
    "                        print(order)\n",
    "                    out['impact_location'] = []\n",
    "                    if out['action'] == '-' or out['action'] == 'R':\n",
    "                        assert len(order.split()) == 4 or len(order.split()) == 5, order\n",
    "                        out['impact_location'] = order.split()[3]\n",
    "                    if unit in results_units_keys:\n",
    "                        results_units_keys.remove(unit)\n",
    "                    yield(out)\n",
    "                \n",
    "            else:\n",
    "                # uncmomment these if you need a row for empty orders (in group by you will get 1 instead of 0)\n",
    "                # out['coordinator'] = player\n",
    "                # out['type'] = -1\n",
    "                # out['current_location'] = -1\n",
    "                # out['action'] = -1\n",
    "                # out['results'] = -1\n",
    "                # out['impact_location'] = -1\n",
    "                # if out['action'] == '-' or out['action'] == 'R':\n",
    "                #     assert len(order.split()) == 4 or len(order.split()) == 5, order\n",
    "                #     out['impact_location'] = order.split()[3]\n",
    "                # yield(out)\n",
    "                pass\n",
    "\n",
    "    if len(results_units_keys)>0:\n",
    "        results_units_values = [input['results'][x] for x in results_units_keys]\n",
    "        total_len = 0\n",
    "        is_movement = True if out['phase_name'][-1] == 'M' else False\n",
    "        for l in results_units_values:\n",
    "                total_len += len(l)\n",
    "        # if we are in the last movement phase, the results are not meaningful\n",
    "        for unit in results_units_keys:\n",
    "            if unit == 'WAIVE': ## FIXME: double check this later\n",
    "                continue\n",
    "            assert len(unit.split()) == 2, unit\n",
    "            if not (total_len == 0 and is_movement):\n",
    "                out['coordinator'] = 'RA'\n",
    "            else:\n",
    "                for player in input[\"state\"][\"units\"]:\n",
    "                    if unit in input[\"state\"][\"units\"][player]:\n",
    "                        out['coordinator'] = player\n",
    "\n",
    "            if len(unit.split()[0]) != 1: # if we have sth like HOL D: \"void\"\n",
    "                assert input['results'][unit][0] == 'void', input['results'][unit]\n",
    "                location = unit.split()[0]\n",
    "                assert unit.split()[1] == 'D', unit.split()[1]\n",
    "                # find the corresponding key in the results\n",
    "                for key in input['results']:\n",
    "                    if key.split()[1] == location:\n",
    "                        assert input['results'][key][0] == \"disband\", input['results'][key]\n",
    "                        input['results'][key].append(input['results'][unit][0])\n",
    "                        break\n",
    "            else:\n",
    "                out['type'] = unit.split()[0]\n",
    "                out['current_location'] = unit.split()[1]\n",
    "                out['results'] = input['results'][unit]\n",
    "                if not (total_len == 0 and is_movement):\n",
    "                    out['action'] = -2 # not in orders and only in result // only happens for \n",
    "                else:\n",
    "                    out['action'] = -3\n",
    "                out['impact_location'] = -2\n",
    "                yield(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = []\n",
    "for idx, game in enumerate(games):\n",
    "  for idx, phase in enumerate(game):\n",
    "    row_generator = flatten_json(phase)\n",
    "    assert row_generator is not None, row_generator\n",
    "    for row in row_generator:\n",
    "      all_records.append(row.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.DataFrame.from_records(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loc[complete_df['coordinator'] == 'RA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['unique_unit_id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glaSz65KoHy4"
   },
   "outputs": [],
   "source": [
    "def assign_unit_id(phase_df, source_unit_id_map, dest_unit_id_map, _id, discard_disband_creation=False):\n",
    "\n",
    "    # fror each row in the phase df\n",
    "    for idx, row in phase_df.iterrows():\n",
    "\n",
    "        # if current location or type of army in invalid skip the row (we only deal with valid orders)\n",
    "        if row['action'] == -1 or row['action'] == -2 or row['type'] == 'N':\n",
    "            continue\n",
    "        \n",
    "        # get the current location of the unit\n",
    "        source_unit = (row['type'] + ' ' + row['current_location'], row['coordinator'])\n",
    "\n",
    "        # if the location is not in the map, add it to the map (in other phases the same unit can be used, hence checking the condition _ dictionaries are global, have data across phases)\n",
    "        if source_unit not in source_unit_id_map:\n",
    "            # if discard_disband_creation:\n",
    "                # if row['action'] == 'D':\n",
    "                #     print(\"disbanding a unit that does not exist\", row)\n",
    "                    # continue\n",
    "            source_unit_id_map[source_unit] = _id\n",
    "            _id += 1\n",
    "\n",
    "        # destination dict is synced with source dict after the loop, so that we can use updated info at the beginning of each assignment\n",
    "        phase_df.loc[idx,'unique_unit_id'] = source_unit_id_map[source_unit]\n",
    "\n",
    "        if row['action'] == '-':\n",
    "            result = row['results']\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    try:\n",
    "                        dest_unit = (row['type'] + ' ' + row['impact_location'], row['coordinator'])\n",
    "                    except:\n",
    "                        print(\"dest location error\", row)\n",
    "                        return\n",
    "                    if dest_unit not in dest_unit_id_map:\n",
    "                        dest_unit_id_map[dest_unit] = source_unit_id_map.pop(source_unit)\n",
    "                elif 'disband' in result:\n",
    "                    Exception(\"move with disband result\")\n",
    "                    # source_unit_id_map.pop(source_unit)\n",
    "                    \n",
    "        elif row['action'] == 'R':\n",
    "            result = row['results']\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    dest_unit = (row['type'] + ' ' + row['impact_location'], row['coordinator'])\n",
    "                    if dest_unit not in dest_unit_id_map:\n",
    "                        dest_unit_id_map[dest_unit] = source_unit_id_map.pop(source_unit)\n",
    "                elif 'disband' in result:\n",
    "                    if len(result) > 1:\n",
    "                        if 'void' in result:\n",
    "                                print(result)\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "\n",
    "        elif row['action'] == 'D':\n",
    "            result = row['results']\n",
    "            # if row.phase_id == 23:\n",
    "            # print(result, \"here\")\n",
    "            # print(result, type(result),isinstance(result, list), \"no\")\n",
    "            assert source_unit in source_unit_id_map\n",
    "            if isinstance(result, list):\n",
    "                if len(result) == 0:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                    # del source_unit_id_map[source_unit]\n",
    "                    # if row.phase_id == 23:\n",
    "                    # print(\"popped it out\")\n",
    "                elif 'disband' in result:\n",
    "                    source_unit_id_map.pop(source_unit)\n",
    "                elif 'void' in result:\n",
    "                    print(\"void disband\", row)\n",
    "            else:\n",
    "                 print(result, type(result),isinstance(result, list), \"yes\")\n",
    "        \n",
    "        elif row['action'] == 'B':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        elif row['action'] == 'H':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        elif row['action'] == 'S':\n",
    "            assert source_unit in source_unit_id_map\n",
    "        \n",
    "        elif row['action'] == 'C':\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        # for added result rows\n",
    "        elif row['action'] == -2:\n",
    "            pass\n",
    "            # result = row['results']\n",
    "            # assert source_unit in source_unit_id_map\n",
    "            # if isinstance(result, list):\n",
    "            #     if len(result) == 0:\n",
    "            #         source_unit_id_map.pop(source_unit)\n",
    "            #     # elif 'disband' in result and 'void' not in result:\n",
    "            #     #     source_unit_id_map.pop(source_unit)\n",
    "            #     # elif 'disband' in result and 'void' in result:\n",
    "            #     #     source_unit_id_map.pop(source_unit)\n",
    "            #     elif 'disband' in result:\n",
    "            #         source_unit_id_map.pop(source_unit)\n",
    "            #     else:\n",
    "            #         print(\"unknown result\", result)\n",
    "\n",
    "        elif row['action'] == -3:\n",
    "            assert source_unit in source_unit_id_map\n",
    "\n",
    "        else:\n",
    "            print(\"invalid action\", row)\n",
    "\n",
    "    # merge the source and destination dictionaries into one\n",
    "    source_unit_id_map.update(dest_unit_id_map)\n",
    "    # remove the destination dict (values get updated based on old data if we don't do this)\n",
    "    dest_unit_id_map = {}\n",
    "\n",
    "    return source_unit_id_map, dest_unit_id_map, _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games = complete_df[\"game_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_games = ['NxMelzPAbZMYgrHY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dislodged_units(phases_cdf, dislodged_df):\n",
    "    for idx, row in dislodged_df.iterrows():\n",
    "        cond = phases_cdf[\"game_id\"].apply(lambda x: x == row.game_id) & phases_cdf[\"type\"].apply(lambda x: x == row.type) & phases_cdf[\"current_location\"].apply(lambda x: x == row.current_location) & phases_cdf[\"phase_id\"].apply(lambda x: x < row.phase_id) & phases_cdf[\"results\"].apply(lambda x: 'dislodged' in x)\n",
    "        assert phases_cdf.loc[cond].empty == False, (game_id, row)\n",
    "        c = phases_cdf.loc[cond].iloc[-1]['coordinator']\n",
    "        phases_cdf.loc[idx,'coordinator'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_phase_df_list = []\n",
    "for idx, game_id in enumerate(unique_games):\n",
    "    phases_df_list = []\n",
    "    print(idx, game_id)\n",
    "    s_dict = {}\n",
    "    d_dict = {}\n",
    "    _id = 1\n",
    "    game_df = complete_df.loc[complete_df[\"game_id\"].apply(lambda x: x == game_id)]\n",
    "    unique_phases = game_df['phase_id'].unique()\n",
    "    for phase in unique_phases:\n",
    "        condition = game_df[\"phase_id\"].apply(lambda x: x == phase)\n",
    "        phase_df = game_df.loc[condition]\n",
    "        s_dict, d_dict, _id = assign_unit_id(phase_df, s_dict, d_dict, _id, discard_disband_creation=False)\n",
    "        # print(phase, s_dict)\n",
    "        # print(d_dict)\n",
    "        phases_df_list.append(phase_df)\n",
    "    phases_cdf = pd.concat(phases_df_list)\n",
    "    dislodged_df = phases_cdf.loc[phases_cdf['action'] == -2].copy()\n",
    "    replace_dislodged_units(phases_cdf, dislodged_df)\n",
    "    game_phase_df_list.append(phases_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf = pd.concat(game_phase_df_list, ignore_index=True)\n",
    "cdf = pd.concat(game_phase_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cdf.loc[cdf['coordinator'] == 'RA'].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.loc[cdf['action'] == -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loc[complete_df['coordinator'] == 'RA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the concatenated df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce to only 2 seasons per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_fall_phases=(cdf['phase_name'].apply(lambda x:x[0])!='W') & (cdf['phase_name'].apply(lambda x:x[-1])!='R') & (cdf['phase_name'].apply(lambda x:x[-1]) == 'M')\n",
    "cdf_sf = cdf.loc[spring_fall_phases].copy()\n",
    "cdf_sf['phase_num']=cdf_sf.phase_name.apply(lambda x: float(x[1:-1]+('.0' if x[0]=='S' else '.5')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute a binary winner label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_series=pd.Series(index=cdf.game_id.unique())\n",
    "for game_id in winner_series.index:\n",
    "    tmax=cdf_sf.loc[cdf_sf.game_id==game_id].phase_num.max()\n",
    "    final_units=cdf_sf.loc[(cdf_sf.game_id==game_id) & (cdf_sf.phase_num==tmax)].groupby('coordinator').unique_unit_id.nunique()\n",
    "    winner_series[game_id]=final_units.idxmax() if len(final_units)>0 else np.nan\n",
    "def dummy(row,winner_series):\n",
    "    return row.coordinator==winner_series[row.game_id]\n",
    "from functools import partial\n",
    "part_dummy=partial(dummy,winner_series=winner_series)\n",
    "cdf_sf['winner']=cdf_sf.apply(part_dummy,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view winning stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute winner loser plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitcounts=cdf_sf.groupby([\"game_id\",\"coordinator\",\"phase_num\",\"winner\"])[\"unique_unit_id\"].nunique()\n",
    "# winlose_data.groupby(['winner','phase_name']).mean().unstack().T.plot(legend=False,xticks=np.arange(1900,1920,5))\n",
    "fig,ax=pl.subplots(1,1,figsize=(5,5))#ensemble statistics\n",
    "sns.lineplot(ax=ax,\n",
    "             x='phase_num',\n",
    "             y='unique_unit_id',\n",
    "             data=unitcounts.reset_index().drop(labels=['game_id','coordinator'],axis=1),\n",
    "             hue=r'winner',\n",
    "             ci='sd',\n",
    "             palette=sns.color_palette(\"colorblind\", 2))\n",
    "h,l=ax.get_legend_handles_labels()\n",
    "ax.legend(handles=h[1:][::-1],labels=['winners','losers'],frameon=False)\n",
    "ax.grid()\n",
    "ax.set_yticks(np.arange(0,20,2))\n",
    "ax.set_yticklabels([0,'',4,'',8,'',12,'',16,''])\n",
    "ax.set_xticks(np.arange(1901,1919,4))\n",
    "ax.set_ylabel('number of units')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylim(0,18)\n",
    "ax.set_xlim(1901,1918)\n",
    "# fig.savefig('winners_and_losers.pdf',format='pdf',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data for different games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loc[complete_df[\"game_id\"] == 'uXFQ2zgI-DUrgwlS']['phase_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.loc[cdf['coordinator'] == 'RA'][:40].sort_values(by=['phase_id', 'unique_unit_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_fall_phases=(cdf['phase_name'].apply(lambda x:x[0])!='W') & (cdf['phase_name'].apply(lambda x:x[-1])!='R') & (cdf['phase_name'].apply(lambda x:x[-1]) == 'M')\n",
    "cdf[spring_fall_phases].groupby([\"game_id\",\"coordinator\",\"phase_name\"])[\"unique_unit_id\"].nunique().unstack().T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[spring_fall_phases].groupby([\"game_id\",\"coordinator\",\"phase_name\"])[\"unique_unit_id\"].nunique().unstack().head(14)\n",
    "cdf.groupby([\"game_id\",\"coordinator\",\"phase_id\"])[\"unique_unit_id\"].nunique().unstack().head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd=(cdf['phase_name'].apply(lambda x:x[0])!='W') & (cdf['phase_name'].apply(lambda x:x[-1])!='R') & (cdf['game_id'].apply(lambda x: x == '0yv59hl6e5Ensb4M') )\n",
    "cdf[cnd].groupby([\"game_id\",\"coordinator\",\"phase_id\"])[\"unique_unit_id\"].nunique().unstack().head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[spring_fall_phases].loc[cdf[\"game_id\"] == \"0yv59hl6e5Ensb4M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a single game to JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = \"NxMelzPAbZMYgrHY\"\n",
    "for game in games_jsons:\n",
    "    if game['id'] == game_id:\n",
    "        json.dump(game, open(f'{game_id}.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate different triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single game:\n",
    "game_id = \"lVp6PZxk3Jpufc9Z\"\n",
    "game_df = cdf.loc[cdf[\"game_id\"] == game_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_fall_phases = (game_df['phase_name'].apply(lambda x:x[-1]) == 'M')\n",
    "game_df = game_df.loc[spring_fall_phases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[\"phase_num\"] = game_df.phase_name.apply(lambda x: float(x[1:-1]+('.0' if x[0]=='S' else '.5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[\"unique_unit_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[\"unique_unit_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.loc[game_df[\"unique_unit_id\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = game_df[\"coordinator\"].unique()\n",
    "assert len(players) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_units = {}\n",
    "for player in players:\n",
    "    player_units[player] = game_df.loc[game_df[\"coordinator\"] == player][\"unique_unit_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/45655936/how-to-test-all-items-of-a-list-are-disjoint\n",
    "# make sure some units are handed over to other players\n",
    "\n",
    "import itertools\n",
    "def all_disjoint(iterables):\n",
    "    merged = itertools.chain(*iterables)\n",
    "    total = list(merged)\n",
    "    total.sort()\n",
    "    print(total)\n",
    "    print(set(total))\n",
    "    return len(total) == len(set(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_units = list(player_units.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disjoint(all_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_two_players = set(itertools.permutations(player_units.keys(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_two_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Triple = namedtuple('Triple', ['triple', 'player_i', 'player_j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "for player_i, player_j in unique_two_players:\n",
    "    p_units = list(itertools.combinations(player_units[player_i], 2))\n",
    "    o_unit = list(itertools.combinations(player_units[player_j], 1))\n",
    "    # get all 3-tuples unique combinations\n",
    "    p_o_product = list(itertools.product(p_units, o_unit))\n",
    "    p_o_product = [(a, b, c) for (a,b), (c,) in p_o_product]\n",
    "    # triple = [Triple(t, player_i, player_j) for t in p_o_product]\n",
    "    triple = [dict(triple=t, player_i=player_i, player_j=player_j) for t in p_o_product]\n",
    "    triples.extend(triple)\n",
    "    # first tuple in the product belongs to player_i and the other belongs to player_j\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in triples:\n",
    "    print(triple)\n",
    "    condition_i = (game_df[\"unique_unit_id\"].apply(lambda x: x in triple['triple'][:2])) & (game_df[\"coordinator\"].apply(lambda x: x == triple['player_i']))\n",
    "    condition_j = (game_df[\"unique_unit_id\"].apply(lambda x: x in triple['triple'][2:])) & (game_df[\"coordinator\"].apply(lambda x: x == triple['player_j']))\n",
    "    presence = game_df.loc[condition_i | condition_j]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence.sort_values(['unique_unit_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = presence[\"phase_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (phases == 3).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_phases = presence.loc[presence[\"phase_name\"].apply(lambda x: mask[x])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_unqiue__eligible_phases = eligible_phases.phase_num.unique()\n",
    "sorted_unqiue__eligible_phases.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_unqiue__eligible_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_phases.phase_num.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples(game_df):\n",
    "    players = game_df[\"coordinator\"].unique()\n",
    "    assert len(players) == 7, players\n",
    "    player_units = {}\n",
    "    for player in players:\n",
    "        player_units[player] = game_df.loc[game_df[\"coordinator\"] == player][\"unique_unit_id\"].unique()\n",
    "    \n",
    "    triples = []\n",
    "    unique_two_players = set(itertools.permutations(player_units.keys(), 2))\n",
    "    for player_i, player_j in unique_two_players:\n",
    "        p_units = list(itertools.combinations(player_units[player_i], 2))\n",
    "        o_unit = list(itertools.combinations(player_units[player_j], 1))\n",
    "        # get all 3-tuples unique combinations\n",
    "        p_o_product = list(itertools.product(p_units, o_unit))\n",
    "        p_o_product = [(a, b, c) for (a,b), (c,) in p_o_product]\n",
    "        triple = [dict(triple=t, player_i=player_i, player_j=player_j) for t in p_o_product]\n",
    "        triples.extend(triple)\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples_presence(game_df, triples):\n",
    "    empty_eligible_phaes = 0\n",
    "    for triple in triples:\n",
    "        condition_i = (game_df[\"unique_unit_id\"].apply(lambda x: x in triple['triple'][:2])) & (game_df[\"coordinator\"].apply(lambda x: x == triple['player_i']))\n",
    "        condition_j = (game_df[\"unique_unit_id\"].apply(lambda x: x in triple['triple'][2:])) & (game_df[\"coordinator\"].apply(lambda x: x == triple['player_j']))\n",
    "        presence = game_df.loc[condition_i | condition_j]\n",
    "        phases = presence[\"phase_name\"].value_counts()\n",
    "        mask = (phases == 3).to_dict()\n",
    "        eligible_phases = presence.loc[presence[\"phase_name\"].apply(lambda x: mask[x])]\n",
    "        unqiue_eligible_phases = eligible_phases.phase_num.unique()\n",
    "        max_phase_num = eligible_phases.phase_num.max()\n",
    "        min_phase_num = eligible_phases.phase_num.min()\n",
    "        max_min_diff = max_phase_num - min_phase_num\n",
    "        if len(unqiue_eligible_phases):\n",
    "            assert (max_min_diff/0.5 + 1) == len(unqiue_eligible_phases) , (\"values are not contiguous\", len(unqiue_eligible_phases), unqiue_eligible_phases, max_min_diff, game_df[\"game_id\"].unique(), triple)\n",
    "        else:\n",
    "            empty_eligible_phaes += 1\n",
    "        triple['max_phase_num'] = max_phase_num\n",
    "        triple['min_phase_num'] = min_phase_num\n",
    "        triple['max_min_diff'] = max_min_diff\n",
    "    return empty_eligible_phaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_tiple_presence = {}\n",
    "for game_id in unique_games:\n",
    "    assert type(game_id) is str, (game_id, \"is not a string\")\n",
    "    print(game_id)\n",
    "    game_df = cdf_sf.loc[cdf_sf['game_id'] == game_id]\n",
    "    # try:\n",
    "        # assert game_df.unique_unit_id.nunique() == game_df.unique_unit_id.max(), (game_id, game_df.unique_unit_id.nunique(), game_df.unique_unit_id.max())\n",
    "    if game_df.unique_unit_id.nunique() == game_df.unique_unit_id.max():\n",
    "        triples = get_triples(game_df)\n",
    "        try:\n",
    "            emp = get_triples_presence(game_df, triples)\n",
    "            print(emp, len(triples))\n",
    "            game_tiple_presence[game_id] = triples\n",
    "        except AssertionError as msg:\n",
    "            print(msg)\n",
    "    # else:\n",
    "        # AssertionError(\"game_id: {}\".format(game_id))\n",
    "    # except AssertionError as msg:\n",
    "    #     print(msg)\n",
    "    #     print(game_df.unique_unit_id.nunique() == game_df.unique_unit_id.max())\n",
    "        # diff = set(np.arange(1, game_df.unique_unit_id.max()+1).tolist()) - set(game_df.unique_unit_id.unique().tolist())\n",
    "        # full_game_df = cdf.loc[cdf['game_id'] == game_id]\n",
    "        # row = full_game_df.loc[full_game_df[\"unique_unit_id\"].apply(lambda x: x in diff)]\n",
    "        # print(list(diff))\n",
    "        # print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = cdf_sf.loc[cdf_sf['game_id'] == \"NxMelzPAbZMYgrHY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df_2 = cdf.loc[cdf['game_id'] == \"NxMelzPAbZMYgrHY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.loc[game_df[\"phase_num\"] == 1906.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df_2.loc[game_df_2[\"unique_unit_id\"] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.loc[game_df[\"phase_id\"] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df_2.loc[game_df_2[\"phase_id\"] == 23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Deepmind's Diplomacy trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_outputs = np.load(file='../data/actions_outputs.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_outputs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(action_outputs[0][0]).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions = np.load(file='../data/legal_actions.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legal_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_actions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.load(file='../data/observations.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_outputs = np.load(file='../data/step_outputs.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(step_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_outputs[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "519c3646e46e87a9b4521f30b0c71a5bab07601a45b52f63f01adb46cf5a2090"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
